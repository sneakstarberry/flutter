# HTTP

### 1.1. Tim Berners-Lee

Http를 개발한 영국의 컴퓨터 엔지니어로 하이퍼텍스트를 개발했고, URL, HTTP, HTML을 설계했다. HTTP와 HTML, 하이퍼 텍스트의 영향이 워낙 강력하고 광범위해서 **인터넷의 아버지**라고 불린다.

### 1.2. HTTP에 대하여

HTTP(Hypertext Transfer Protocol)은 인터넷상에서 데이터를 주고 받기 위한 서버/클라이언트 모델을 따르는 프로토콜이다. 어플리케이션 레벨의 프로토콜로 TCP/IP위에서 작동한다.

 HTTP는 어떤 종류의 데이터든지 전송할 수 있도록 설계되어 있다. 인터넷상에서 흔히  볼 수 있는 HTML로 작성된 무서는 HTTP로 보낼 수 있는 데이터의 한 종류일 뿐이다. 이미지, 동영상, 오디오, 텍스트 문서 등 종류를 가리지 않는다.

### 1.3. 작동 방식

server/client 모델을 따른다. 클라이언트에서 요청(request)를 보내면 서버는 요청을 처리해서 응답(response)한다.

1. 클라이언트: 서버에 **요청하는 클라이언트 소프트웨어**가 설치된 컴퓨터. chrome, firefox, ie 등의 클라이언트 소프트웨어를 이용한다. 클라이언트는 URI를 이용해서 서버에 접속하고, 데이터를 요청할 수 있다.
2. 서버: 클라이언트의 요청을 받아서, 요청을 해석하고 응답을 하는 소프트웨어가 설치된 컴퓨터.

### 1.4. 특징

#### 1.4.1. Connectless & Stateless

HTTP는 Connectless 방식으로 작동한다. 서버에 연결하고, 요청해서 응답을 받으면 연결을 끊어버린다. 기본적으로는 자원 하나에 대해서 하나의 연결을 만든다. 이런 작동방식은 각각 아래의 장점과 단점을 가진다.

- 장점 : 불특정 다수를 대상으로 하는 서비스에 적합한 방식이다. 수십만명이 웹 서비스를 사용하더라도 접속유지는 최소한으로 할 수 있기 때문에, 더 많은 유저의 요청을 처리할 수 있다.
- 단점 : 연결을 끊어버리기 때문에, 클라이언트의 이전 상태를 알 수가 없다. 이러한 HTTP의 특징을 **stateless**라고 하는데, Connectless로 부터 파생되는 특징이라고 할 수 있다. **클라이언트의 이전 상태** 정보를 알 수 없게 되면, 웹 서비스를 하는데 당장에 문제가 생긴다. 예컨데, 클라이언트가 과거에 로그인을 성공하더라도 로그 정보를 유지할 수가 없다. HTTP는 **cookie**를 이용해서 이 문제를 해결하고 있다.

**Cookie**는 클라이언트와 서버의 상태 정보를 담고 있는 정보조각이다. 로그인을 예로 들자면, 클라이언트가 로그인에 성공하면, 서버는 로그인 정보를 자신의 데이터베이스에 저장하고 동일한 값을 **cookie**형태로 클라이언트에 보낸다. 클라이언트는 다음 번 요청때 cookie를 서버에 보내는데, 서버는 cookie 값으로 자신의 데이터베이스를 조회해서 로그인 여부를 확인할 수 있다. 자세한 내용은 다음 세션 관리에서 다룬다.

#### 1.4.2 Method(메서드)

메서드는 요청의 종류를 서버에게 알려주기 위해서 사용한다. 다음은 요청에 사용할 수 있는 메서드들이다.

- GET : 정보를 요청하기 위해서 사용한다. (SELECT)
- POST : 정보를 밀어넣기 위해서 사용한다. (INSERT)
- PUT : 정보를 업데이트하기 위해서 사용한다. (UPDATE)
- DELETE : 정보를 삭제하기 위해서 사용한다. (DELETE)
- HEAD : (HTTP)헤더 정보만 요청한다. 해당 자원이 존재하는지 혹은 서버에 문제가 없는지를 확인하기 위해서 사용한다.
- OPTIONS : 웹서버가 지원하는 메서드의 종류를 요청한다.
- TRACE : 클라이언트의 요청을 그대로 반환한다. 예컨데 echo 서비스로 서버 상태를 확인하기 위한 목적으로 주로 사용한다.

보통 웹 서비스들은 **GET**과 **POST**만을 이용해서 개발한다. DELETE나 PUT등이 필요한 요청에도 GET과 POST를 사용하는데, 예를들어 게시판에서 특정 레코드를 삭제 할때도 GET 으로 표현한다.

각 용도에 맞는 메서드가 준비돼 있음에도 이렇게 사용하는 이유는

1. GET과 POST만으로도 모든 종류의 요청을 표현할 수 있어서
2. 편하게 개발하고 싶어서
3. 웹 브라우저로 DELETE, HEAD등을 보내는 form이 없어서 이다.

#### 1.4.3. 요청 데이터 포멧

웹 브라우저는 웹 서버에 데이터를 "요청"하는 "클라이언트 프로그램" 이다. 요청은 서버가 인식할 수 있는 약속된 형식(HTTP 형식)을 따라야 한다.

요청 데이터는 "HEADER"와 "BODY"로 구성된다.

#### 1.4.4. Keep alive

HTTP는 하나의 연결에 하나의 요청을 하는 것을 기준으로 설계가 됐다. 요즘 웹 서비스의 경우 간단한 페이지라고 해도 수십개의 데이터 - 이미지, 문서, css, javascript - 등이 있기 마련인데, HTTP의 원래 규격대로라면 웹페이지를 하나 표시하기 위해서 연결을 맺고 끝는 과정을 수십번을 반복해야 한다. 당연히 비효율적일 수 밖에 없다. 연결을 맺고 끝는 것은 TCP 통신 과정에서 가장 많은 비용이 소비되는 작업이기 때문이다.

예를들어 HTML로 표현된 문서를 다운로드 받는다고 가정해 보자. 이 문서에는 20여개 정도의 이미지, css, javascript 파일이 있다. Keep alive를 지원하지 않을 경우 다음과 같은 과정을 거친다.

- 웹 서버에 연결한다.
- HTML 문서를 다운로드 한다.
- 웹 서버 연결을 끊는다.
- HTML 문서의 image, css, javascript 링크들을 읽어서 다운로드해야할 경로를 저장한다.
- 웹 서버에 연결한다.
- 첫번째 이미지를 다운로드
- 연결을 끊는다.
- 웹 서버에 연결한다.
- 두번째 이미지를 다운로드
- 연결을 끊는다.
- 모든 링크를 다운로드 할 때까지 반복한다.

Keep-alive 설정을 하면, 지정된 시간동안 연결을 끊지 않고 요청을 계속해서 보낼 수 있다.

- 웹 서버에 연결한다.
- HTML 문서를 다운로드 한다.
- Image, css, javascript 들을 다운로드 한다.
- 모든 문서를 다운로드 받았다면 연결을 끊는다.



